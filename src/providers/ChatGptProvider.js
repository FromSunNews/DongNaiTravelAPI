import axios from 'axios'
import { env } from 'config/environtment'
import { result } from 'lodash'

import { Configuration, OpenAIApi } from 'openai'


const handleItineraryRequest = async (content, io, socketIdMap, currentUserId) => {
  console.log('ðŸš€ ~ file: ChatGptProvider.js:8 ~ handleItineraryRequest ~ currentUserId:', currentUserId)
  console.log('ðŸš€ ~ file: ChatGptProvider.js:8 ~ handleItineraryRequest ~ socketIdMap:', socketIdMap)
  console.log('ðŸš€ ~ file: ChatGptProvider.js:8 ~ handleItineraryRequest ~ io:', io)
  console.log('ðŸš€ ~ file: ChatGptProvider.js:8 ~ handleItineraryRequest ~ content:', content)
  try {
    const configuration = new Configuration({
      apiKey: env.CHATGPT_API_KEY
    })

    const openai = new OpenAIApi(configuration)

    const completion = await openai.createChatCompletion({
      model: 'gpt-3.5-turbo', // Chá»n model phÃ¹ há»£p
      messages: [{ role: 'user', content: content }], // cáº¥u hÃ¬nh role vÃ  content mÃ¬nh muá»‘n há»i
      temperature: 0, // Äáº§u ra táº­p trung vÃ o vÃ o cÃ¢u há»i nhiá»u hÆ¡n
      stream: true // NÃ³ sáº½ tráº£ dá»¯ liá»‡u vá» theo tá»«ng Ä‘á»t
    }, {
      responseType: 'stream'
    })
    let messageReturn = ''
    completion.data.on('data', (data) => {
      const lines = data
        ?.toString()
        ?.split('\n')
        .filter((line) => line.trim() !== '')
      for (const line of lines) {
        const message = line.replace(/^data: /, '')
        if (message === '[DONE]') {
          io.to(socketIdMap[currentUserId]).emit('s_create_travel_itinerary', {
            messageReturn: 'DONE'
          })
          break // Stream finished
        }
        try {
          const parsed = JSON.parse(message)
          if (parsed.choices[0].delta.content) {
            messageReturn += parsed.choices[0].delta.content
            console.log(messageReturn)
            io.to(socketIdMap[currentUserId]).emit('s_create_travel_itinerary', {
              messageReturn: parsed.choices[0].delta.content
            })
          }
        } catch (error) {
          console.error('Could not JSON parse stream message', message, error)
        }
      }
    })
  } catch (error) {
    console.log(error)
  }
}

const textGenerationTest = async (queryText) => {
  try {
    const configuration = new Configuration({
      apiKey: env.CHATGPT_API_KEY
    })

    const openai = new OpenAIApi(configuration)

    const completion = await openai.createChatCompletion({
      model: 'gpt-3.5-turbo', // Chá»n model phÃ¹ há»£p
      messages: [{ 'role': 'system', 'content': 'Báº¡n lÃ  ráº¥t giá»i ngÆ°á»i láº­p káº¿ hoáº¡ch chuyáº¿n Ä‘i. Vui lÃ²ng táº¡o káº¿ hoáº¡ch chuyáº¿n Ä‘i tá»« tin nháº¯n cá»§a ngÆ°á»i dÃ¹ng. Lá»™ trÃ¬nh trong ngÃ y chia lÃ m 3 buá»•i sÃ¡ng, trÆ°a, chiá»u, trong Ä‘Ã³ báº¡n pháº£i nÃªu Ä‘á»‹a Ä‘iá»ƒm tham quan vÃ  miÃªu táº£ ngáº¯n gá»n báº±ng vÄƒn nÃ³i. bÃ n cáº§n Ä‘á»‹nh dáº¡ng cÃ¡c Ä‘á»‹a Ä‘iá»ƒm theo dáº¡ng [place|province]. Náº¿u báº¡n khÃ´ng cháº¯c Ä‘á»‹a Ä‘iá»ƒm Ä‘Ã³ cÃ³ tá»“n táº¡i thÃ¬ Ä‘á»«ng Ä‘Æ°a ra vÃ  cÃ¡c Ä‘á»‹a Ä‘iá»ƒm pháº£i khÃ¡c nhau khÃ´ng láº·p láº¡i. Äá»™ dÃ i hÃ nh trÃ¬nh máº·c Ä‘á»‹nh lÃ  nÄƒm ngÃ y náº¿u khÃ´ng Ä‘Æ°á»£c cung cáº¥p. Tráº£ lá»i theo phong cÃ¡ch AI báº±ng tiáº¿ng viá»‡t' }, { role: 'user', content: `Human: ${queryText}\nAI: ` }],
      temperature: 0, // Äáº§u ra táº­p trung vÃ o vÃ o cÃ¢u há»i nhiá»u hÆ¡n
      stream: true // NÃ³ sáº½ tráº£ dá»¯ liá»‡u vá» theo tá»«ng Ä‘á»t
    }, {
      responseType: 'stream'
    })
    let messageReturn = ''
    completion.data.on('data', (data) => {
      const lines = data
        ?.toString()
        ?.split('\n')
        .filter((line) => line.trim() !== '')
      for (const line of lines) {
        const message = line.replace(/^data: /, '')
        if (message === '[DONE]') {
          return messageReturn
        }
        try {
          const parsed = JSON.parse(message)
          if (parsed.choices[0].delta.content) {
            messageReturn += parsed.choices[0].delta.content
            console.log(messageReturn)
          }
        } catch (error) {
          console.error('Could not JSON parse stream message', message, error)
        }
      }
    })
  } catch (error) {
    console.log(error)
  }
}

// const textGenerationTest = async (queryText) => {
//   console.log('ðŸš€ ~ file: ChatGptProvider.js:61 ~ textGeneration ~ queryText:', queryText)
//   try {

//     const configuration = new Configuration({
//       apiKey: env.CHATGPT_API_KEY
//     })

//     const openai = new OpenAIApi(configuration)

//     const completion = await openai.createChatCompletion({
//       model: 'gpt-3.5-turbo',
//       messages: [{ 'role': 'system', 'content': 'You are the best itinerary planner. Please only create itinerary from user messages. The itinerary in a day is divided into 3 mornings, noon and afternoon in which you have to give places to visit and a short description in oral form. You need to format your response by adding [] around locations with province separated by pipe. The default itinerary length is five days if not provided. Answer in AI style by Vietnamese' }, { role: 'user', content: `Human: ${queryText}\nAI: ` }],
//       temperature: 0.2
//     })
//     console.log(completion.data.choices[0].message)
//     return completion.data.choices[0].message
//   } catch (error) {
//     console.log('ðŸš€ ~ file: ChatGptProvider.js:79 ~ textGenerationTest ~ error:', error)
//     return {
//       response: 'Sorry, I\'m not able to help with that.'
//     }
//   }
// }

const textGeneration = async (queryText) => {
  console.log('ðŸš€ ~ file: ChatGptProvider.js:61 ~ textGeneration ~ queryText:', queryText)
  try {

    const configuration = new Configuration({
      apiKey: env.CHATGPT_API_KEY
    })

    const openai = new OpenAIApi(configuration)

    const response = await openai.createCompletion({
      model: 'text-davinci-003',
      prompt: `Human: ${queryText}\nAI: `,
      temperature: 0.1,
      max_tokens: 3500,
      top_p: 1,
      frequency_penalty: 0,
      presence_penalty: 0.6,
      stop: ['Human:', 'AI:']
    })
    return {
      response: `${response.data.choices[0].text}`.trimStart()
    }
  } catch (error) {
    return {
      response: 'Sorry, I\'m not able to help with that.'
    }
  }
}

export const ChatGptProvider = {
  handleItineraryRequest,
  textGeneration,
  textGenerationTest
}